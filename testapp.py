import streamlit as st
import google.generativeai as genai
from pypdf import PdfReader
import requests
from bs4 import BeautifulSoup
from googlesearch import search
from io import BytesIO
import json
import re
import tempfile
import time

# --- 1. Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£ ---
st.set_page_config(page_title="Legislative Auditor AI (Fail-safe)", page_icon=":balance_scale:", layout="wide")

st.markdown("""
<style>
    .score-card { background-color: #e8f5e9; padding: 20px; border-radius: 10px; text-align: center; border: 2px solid #2e7d32; }
    .big-score { font-size: 48px; font-weight: bold; color: #2e7d32; }
    .stButton>button { width: 100%; background-color: #1565C0; color: white; border-radius: 5px; }
    .manual-badge { background-color: #e0f7fa; color: #006064; padding: 4px 8px; border-radius: 4px; font-size: 0.8em; border: 1px solid #006064;}
</style>
""", unsafe_allow_html=True)

st.title("âš–ï¸ Legislative Auditor AI")
st.caption("V24: ÎœÎµ ÏƒÏÏƒÏ„Î·Î¼Î± Î±ÏƒÏ†Î±Î»ÎµÎ¯Î±Ï‚ (Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· Ï‡ÏÎ®ÏƒÎ· Link Î±Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Ï„Î¿ API)")

# --- 2. SIDEBAR ---
with st.sidebar:
    st.header("Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")
    api_key = None
    try:
        if "GEMINI_API_KEY" in st.secrets:
            api_key = st.secrets["GEMINI_API_KEY"]
            st.success("âœ… API Key loaded!")
    except: pass

    if not api_key:
        api_key = st.text_input("Google Gemini API Key", type="password")
    
    if api_key: 
        genai.configure(api_key=api_key)

# --- 3. FUNCTIONS ---

def get_law_from_api(lawnum):
    """Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ API."""
    url = "https://www.hellenicparliament.gr/api.ashx"
    params = {"q": "laws", "lawnum": lawnum, "format": "json"}
    try:
        r = requests.get(url, params=params, timeout=10)
        data = r.json()
        if data.get('TotalRecords', 0) > 0:
            return data['Data'][0]
    except: pass
    return None

def scrape_law_from_url(url):
    """
    FALLBACK: Î‘Î½ Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹ Ï„Î¿ API, Î¼Ï€Î±Î¯Î½ÎµÎ¹ ÏƒÏ„Î· ÏƒÎµÎ»Î¯Î´Î± ÎºÎ±Î¹ Î²ÏÎ¯ÏƒÎºÎµÎ¹ Ï„Î± PDF Ï‡ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î±.
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î­Î½Î± ÏˆÎµÏÏ„Î¹ÎºÎ¿ Î±Î½Ï„Î¹ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Ï€Î¿Ï… Î¼Î¿Î¹Î¬Î¶ÎµÎ¹ Î¼Îµ Ï„Î¿Ï… API.
    """
    if not url: return None
    print(f"Scraping Manual URL: {url}")
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15)
        soup = BeautifulSoup(r.content, 'html.parser')
        
        # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± ÎµÏÏÎµÏƒÎ·Ï‚ Ï„Î¯Ï„Î»Î¿Ï…
        title = "Î§ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î· Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ· ÎÏŒÎ¼Î¿Ï…"
        h1 = soup.find("h1")
        if h1: title = h1.get_text().strip()
        
        # Î•ÏÏÎµÏƒÎ· PDF Links
        files_list = []
        for a in soup.find_all('a', href=True):
            href = a['href']
            txt = a.get_text().strip()
            
            if ".pdf" in href:
                # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ URL
                if not href.startswith("http"):
                    href = "https://www.hellenicparliament.gr" + href
                
                # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î¼Î±Î½Ï„ÎµÏˆÎ¹Î¬Ï‚ Ï„ÏÏ€Î¿Ï… Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î±Ï€ÏŒ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï„Î¿Ï… link Î® Ï„Î¿ filename
                ftype = "Î‘ÏÏ‡ÎµÎ¯Î¿ ÎÏŒÎ¼Î¿Ï…/ÎˆÎºÎ¸ÎµÏƒÎ·Ï‚"
                if "Î±Î¹Ï„Î¹Î¿Î»Î¿Î³Î¹ÎºÎ®" in txt.lower(): ftype = "Î‘Î¹Ï„Î¹Î¿Î»Î¿Î³Î¹ÎºÎ® ÎˆÎºÎ¸ÎµÏƒÎ·"
                elif "ÏƒÏ…Î½ÎµÏ€ÎµÎ¹ÏÎ½" in txt.lower(): ftype = "Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½ÎµÏ€ÎµÎ¹ÏÎ½ (Î‘Î£Î¥Î¡)"
                elif "Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¯Î±" in txt.lower(): ftype = "Î¤ÏÎ¿Ï€Î¿Î»Î¿Î³Î¯Î±"
                elif "Î½ÏŒÎ¼Î¿Ï‚" in txt.lower() or "ÏˆÎ·Ï†Î¹ÏƒÎ¸Î­Î½" in txt.lower(): ftype = "ÎšÎµÎ¯Î¼ÎµÎ½Î¿ ÎÏŒÎ¼Î¿Ï…"
                
                files_list.append({
                    "File": href,
                    "FileType": ftype
                })
        
        if files_list:
            return {
                "Title": title,
                "LawPhotocopy": files_list,
                "DateInserted": "Î†Î³Î½Ï‰ÏƒÏ„Î¿ (Scraped)",
                "DateVoted": "Î†Î³Î½Ï‰ÏƒÏ„Î¿ (Scraped)"
            }
            
    except Exception as e:
        print(f"Scraping Error: {e}")
        return None
    return None

def find_opengov_smart(law_title):
    stopwords = ["ÎšÏÏÏ‰ÏƒÎ·", "Î•Î½ÏƒÏ‰Î¼Î¬Ï„Ï‰ÏƒÎ·", "Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚", "Î”Î¹Î±Ï„Î¬Î¾ÎµÎ¹Ï‚", "Ï„Î¿Ï…", "Ï„Î·Î½", "ÎºÎ±Î¹", "Î³Î¹Î±", "Î¼Îµ"]
    words = law_title.split()
    keywords = [w for w in words if len(w) > 3 and w not in stopwords]
    search_query = " ".join(keywords[:6])
    query = f"site:opengov.gr {search_query}"
    try:
        for url in search(query, num_results=2):
            if "opengov.gr" in url: return url
    except: pass
    return None

def scrape_opengov(url):
    if not url: return ""
    try:
        r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
        soup = BeautifulSoup(r.content, 'html.parser')
        return re.sub(r'\s+', ' ', soup.get_text()).strip()[:20000]
    except: return ""

def ocr_scanned_pdf(file_bytes):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(file_bytes)
            tmp_path = tmp.name  
        uploaded_file = genai.upload_file(tmp_path, mime_type="application/pdf")
        time.sleep(2)
        model = genai.GenerativeModel("models/gemini-2.0-flash")
        response = model.generate_content([uploaded_file, "Extract text verbatim."], request_options={"timeout": 600})
        return response.text
    except: return ""

def process_pdf_smart(url, ftype):
    if not url: return "", "N/A"
    try:
        if not url.startswith("http"): url = "https://www.hellenicparliament.gr" + url
        res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=60)
        file_bytes = res.content
        text_content = ""
        with BytesIO(file_bytes) as f:
            reader = PdfReader(f)
            for page in reader.pages: text_content += page.extract_text() or ""
        clean_txt = re.sub(r'\s+', ' ', text_content).strip()
        
        if len(clean_txt) > 200: return clean_txt, "TEXT"
        else:
            ocr = ocr_scanned_pdf(file_bytes)
            return ocr, "OCR"
    except: return "", "ERR"

def run_auditor_certified(law_text, reports_text, amendments_text, opengov_text, metadata):
    try:
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        knowledge_base = """
        Î’Î‘Î£Î™ÎšÎ•Î£ Î‘Î¡Î§Î•Î£ Î‘Î ÎŸ Î¤ÎŸ Î•Î“Î§Î•Î™Î¡Î™Î”Î™ÎŸ ÎÎŸÎœÎŸÎ Î‘Î¡Î‘Î£ÎšÎ•Î¥Î‘Î£Î¤Î™ÎšÎ—Î£ ÎœÎ•Î˜ÎŸÎ”ÎŸÎ›ÎŸÎ“Î™Î‘Î£ & ÎŸÎ”Î—Î“ÎŸ Î‘Î£Î¥Î¡:
        1. Î— Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½ÎµÏ€ÎµÎ¹ÏÎ½ Î¡ÏÎ¸Î¼Î¹ÏƒÎ·Ï‚ (Î‘Î£Î¥Î¡) Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï…Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ¬: Î•Î½ÏŒÏ„Î·Ï„Î± Î” (Î“ÎµÎ½Î¹ÎºÎ­Ï‚ Î£Ï…Î½Î­Ï€ÎµÎ¹ÎµÏ‚), Î•Î½ÏŒÏ„Î·Ï„Î± Î• (Î”Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·), Î•Î½ÏŒÏ„Î·Ï„Î± Î£Î¤ (ÎÎ¿Î¼Î¹Î¼ÏŒÏ„Î·Ï„Î±).
        2. "Î•Ï€Î¹Ï‡ÏÏÏƒÏ‰ÏƒÎ·" (Gold-plating): Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î²Î±ÏÏÎ½ Ï€Î­ÏÎ±Î½ Ï„Ï‰Î½ Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Ï‰Î½ Î±Ï€ÏŒ Ï„Î·Î½ Î•Î•.
        3. Î”Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·: Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î· Î´Î¹Î¬ÏÎºÎµÎ¹Î± 14 Î·Î¼Î­ÏÎµÏ‚.
        """
        prompt = f"""
        Î•Î½ÎµÏÎ³ÎµÎ¯Ï‚ Ï‰Ï‚ Î Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿Ï‚ ÎÎ¿Î¼Î¹ÎºÏŒÏ‚ Î•Î»ÎµÎ³ÎºÏ„Î®Ï‚ (Certified Auditor).
        ÎšÏÎ¯Î½ÎµÎ¹Ï‚ Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿Î½ "Î”ÎµÎºÎ¬Î»Î¿Î³Î¿ ÎšÎ±Î»Î®Ï‚ ÎÎ¿Î¼Î¿Î¸Î­Ï„Î·ÏƒÎ·Ï‚".
        
        CONTEXT: {knowledge_base}
        METADATA: {metadata}
        OPENGOV: {opengov_text[:15000]}
        ÎÎŸÎœÎŸÎ£: {law_text[:50000]}
        Î•ÎšÎ˜Î•Î£Î•Î™Î£: {reports_text[:80000]}
        Î¤Î¡ÎŸÎ ÎŸÎ›ÎŸÎ“Î™Î•Î£: {amendments_text[:20000]}
        
        ÎšÎ¡Î™Î¤Î—Î¡Î™Î‘ (1=ÎÎ‘Î™, 0.5=ÎœÎ•Î¡Î™ÎšÎ©Î£, 0=ÎŸÎ§Î™). Î”ÏÏƒÎµ score_val ÎºÎ±Î¹ reason.
        1. Î Î¡ÎŸ-ÎšÎŸÎ™ÎÎŸÎ’ÎŸÎ¥Î›Î•Î¥Î¤Î™ÎšÎ— Î”Î™Î‘Î’ÎŸÎ¥Î›Î•Î¥Î£Î— (>14 Î·Î¼Î­ÏÎµÏ‚); (Î¨Î¬Î¾Îµ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚ ÏƒÏ„Î¿ OpenGov Î® ÏƒÏ„Î·Î½ Î‘Î£Î¥Î¡).
        2. Î•ÎšÎ˜Î•Î£Î— Î”Î™Î‘Î’ÎŸÎ¥Î›Î•Î¥Î£Î—Î£ (Î Î¿Î¹ÏŒÏ„Î·Ï„Î±); (Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î·Î½ Î‘Î£Î¥Î¡ Î•Î½ÏŒÏ„Î·Ï„Î± Î•;).
        3. Î§Î¡ÎŸÎÎŸÎ£ Î‘ÎšÎ¡ÎŸÎ‘Î£Î—Î£ Î¦ÎŸÎ¡Î•Î©Î;
        4. Î¤Î¡ÎŸÎ ÎŸÎ›ÎŸÎ“Î™Î•Î£ (Î£Ï…Î½Î¬Ï†ÎµÎ¹Î±/Î§ÏÏŒÎ½Î¿Ï‚);
        5. Î•Î Î™Î§Î¡Î¥Î£Î©Î£Î— (Gold-plating);
        6. ÎÎ—Î£Î™Î©Î¤Î™ÎšÎŸÎ¤Î—Î¤Î‘;
        7. Î‘ÎÎ‘Î›Î¥Î£Î— ÎšÎŸÎ£Î¤ÎŸÎ¥Î£ (Î“Î›Îš);
        8. Î‘Î Î›ÎŸÎ¥Î£Î¤Î•Î¥Î£Î—;
        9. Î•ÎÎŸÎ¥Î£Î™ÎŸÎ”ÎŸÎ¤Î—Î£Î•Î™Î£;
        10. Î ÎŸÎ™ÎŸÎ¤Î—Î¤Î‘ Î“Î›Î©Î£Î£Î‘Î£;

        OUTPUT JSON ONLY: {{ "criteria": [...], "summary": "..." }}
        """
        response = model.generate_content(prompt)
        txt = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(txt.strip())
    except Exception as e: return {"error": str(e)}

# --- 4. UI ---
st.subheader("ğŸ” Î Î»Î®ÏÎ·Ï‚ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ (Fail-Safe)")
col1, col2 = st.columns([1, 1])
with col1: l_input = st.text_input("1. Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎÏŒÎ¼Î¿Ï… (Ï€.Ï‡. 4940)", value="")
with col2: l_link = st.text_input("2. Link Î’Î¿Ï…Î»Î®Ï‚ (Î‘Î½ Î´ÎµÎ½ Ï„Î¿ Î²ÏÎ¯ÏƒÎºÎµÎ¹ Ï„Î¿ API)", placeholder="https://www.hellenicparliament.gr/...")
start = st.button("ğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î‘Î½Î¬Î»Ï…ÏƒÎ·Ï‚", type="primary")

if start:
    if not api_key: st.error("Missing Key"); st.stop()
    status = st.status("âš™ï¸ Î•ÎºÎºÎ¯Î½Î·ÏƒÎ·...", expanded=True)
    
    # --- 1. Î‘ÎÎ‘ÎšÎ¤Î—Î£Î— Î”Î•Î”ÎŸÎœÎ•ÎÎ©Î (API Î® SCRAPING) ---
    law_data = None
    
    # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î‘: API
    if l_input:
        status.write("ğŸ›ï¸ Î”Î¿ÎºÎ¹Î¼Î® Î¼Î­ÏƒÏ‰ API...")
        clean_num = l_input.split("/")[0].strip()
        law_data = get_law_from_api(clean_num)
    
    # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î’: Scraping (Î‘Î½ Î±Ï€Î­Ï„Ï…Ï‡Îµ Ï„Î¿ API)
    if not law_data:
        if l_link:
            status.write("âš ï¸ Î¤Î¿ API Î±Ï€Î­Ï„Ï…Ï‡Îµ. Î”Î¿ÎºÎ¹Î¼Î® Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚ Î±Ï€ÏŒ Ï„Î¿ Link (Scraping)...")
            law_data = scrape_law_from_url(l_link)
        else:
            status.update(label="âŒ ÎŸ ÎÏŒÎ¼Î¿Ï‚ Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ.", state="error")
            st.error("Î¤Î¿ API Î´ÎµÎ½ Î²ÏÎ®ÎºÎµ Ï„Î¿Î½ Î½ÏŒÎ¼Î¿. Î Î±ÏÎ±ÎºÎ±Î»Ï ÎµÏ€Î¹ÎºÎ¿Î»Î»Î®ÏƒÏ„Îµ Ï„Î¿ Link Î±Ï€ÏŒ Ï„Î¿ hellenicparliament.gr ÏƒÏ„Î¿ Ï€ÎµÎ´Î¯Î¿ 2.")
            st.stop()
            
    if not law_data:
        st.error("Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î±Î½Î¬ÎºÏ„Î·ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.")
        st.stop()

    title = law_data.get('Title', 'Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î¤Î¯Ï„Î»Î¿Ï‚')
    st.success(f"**Î’ÏÎ­Î¸Î·ÎºÎµ:** {title}")
    
    # --- 2. OPENGOV ---
    status.write("ğŸŒ Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· OpenGov...")
    og_url = find_opengov_smart(title)
    og_text = scrape_opengov(og_url) if og_url else ""
    if og_url: st.info(f"ğŸ”— OpenGov: {og_url}")

    # --- 3. FILES ---
    status.write("ğŸ“¥ Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· Î‘ÏÏ‡ÎµÎ¯Ï‰Î½...")
    files = law_data.get('LawPhotocopy', [])
    if not files: 
        st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ PDF.")
        st.stop()
        
    txt_law, txt_reports, txt_amendments = "", "", ""
    prog = st.progress(0)
    
    for i, f in enumerate(files):
        url = f.get('File')
        ftype = str(f.get('FileType', '')).lower()
        if url:
            text, mode = process_pdf_smart(url, ftype)
            if text:
                if "Î½ÏŒÎ¼Î¿Ï…" in ftype or "ÏˆÎ·Ï†Î¹ÏƒÎ¸Î­Î½" in ftype: txt_law += text
                elif "Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¯Î±" in ftype: txt_amendments += f"\n--- Î¤Î¡ÎŸÎ ÎŸÎ›ÎŸÎ“Î™Î‘ ---\n" + text
                else: txt_reports += f"\n--- Î•Î“Î“Î¡Î‘Î¦ÎŸ ({ftype}) ---\n" + text
        prog.progress((i + 1) / len(files))

    # --- 4. AUDIT ---
    status.write("ğŸ§  Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·...")
    meta = json.dumps(law_data, ensure_ascii=False)
    res = run_auditor_certified(txt_law, txt_reports, txt_amendments, og_text, meta)
    
    if "error" in res:
        status.update(label="âŒ AI Error", state="error"); st.error(res['error']); st.stop()
        
    status.update(label="âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!", state="complete", expanded=False)
    
    # --- RESULTS ---
    score = sum([c.get('score_val', 0) * 10 for c in res.get('criteria', [])])
    c1, c2 = st.columns([1,2])
    score_html = f"""<div class="score-card"><h3>Î’Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î±</h3><div class="big-score">{int(score)}/100</div></div>"""
    with c1: st.markdown(score_html, unsafe_allow_html=True)
    with c2: st.info(res.get('summary'))
    st.divider()
    
    for c in res.get('criteria', []):
        val = c.get('score_val', 0)
        icon = "âœ…" if val == 1 else ("âš ï¸" if val == 0.5 else "âŒ")
        extra = " <span class='manual-badge'>Î‘Î£Î¥Î¡ Checked</span>" if "Î•Î½ÏŒÏ„Î·Ï„Î±" in c.get('reason', '') else ""
        with st.expander(f"{icon} {c.get('title')} ({int(val*10)}/10)"):
            st.markdown(f"**Î‘Î¹Ï„Î¹Î¿Î»Î¿Î³Î¯Î±:** {c.get('reason')}" + extra, unsafe_allow_html=True)