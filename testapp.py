import os
import time
import requests
import urllib.parse
from bs4 import BeautifulSoup
import google.generativeai as genai

# =============================================================================
# âš™ï¸ Î¡Î¥Î˜ÎœÎ™Î£Î•Î™Î£
# =============================================================================
GOOGLE_API_KEY = "TO_API_KEY_SOY_EDO"  # <--- Î’Î‘Î›Î• Î¤ÎŸ ÎšÎ›Î•Î™Î”Î™ Î£ÎŸÎ¥
DOWNLOAD_FOLDER = "full_audit_downloads" # ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ Î¸Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î·Î¸ÎµÎ¯ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±

# =============================================================================
# ğŸ“œ Î¤ÎŸ Î‘Î ÎŸÎ›Î¥Î¤ÎŸ SYSTEM PROMPT (AUDITOR + LINGUIST + MANUAL CHECKER)
# =============================================================================
SYSTEM_INSTRUCTIONS = """
Î•Î½ÎµÏÎ³ÎµÎ¯Ï‚ Ï‰Ï‚ Î¿ Î‘Î½ÏÏ„Î±Ï„Î¿Ï‚ Î•Î»ÎµÎ³ÎºÏ„Î®Ï‚ Î Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ ÎÎ¿Î¼Î¿Î¸ÎµÏƒÎ¯Î±Ï‚ (Supreme Legislative Auditor).
ÎˆÏ‡ÎµÎ¹Ï‚ ÏƒÏ„Î· Î´Î¹Î¬Î¸ÎµÏƒÎ® ÏƒÎ¿Ï… Ï„Î± Ï€Î»Î®ÏÎ· ÎºÎµÎ¯Î¼ÎµÎ½Î± Ï„Î¿Ï… Î½Î¿Î¼Î¿ÏƒÏ‡ÎµÎ´Î¯Î¿Ï… ÎºÎ±Î¹ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î´Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·Ï‚.

Î— Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® ÏƒÎ¿Ï… ÎµÎ¯Î½Î±Î¹ Î½Î± Î´Î¹ÎµÎ½ÎµÏÎ³Î®ÏƒÎµÎ¹Ï‚ Î­Î½Î±Î½ Î•Î›Î•Î“Î§ÎŸ Î’Î‘Î˜ÎŸÎ¥Î£ (DEEP AUDIT) Î²Î±ÏƒÎ¹ÏƒÎ¼Î­Î½Î¿ ÏƒÎµ 3 Ï€Ï…Î»ÏÎ½ÎµÏ‚.
ÎœÎ·Î½ ÎºÎ¬Î½ÎµÎ¹Ï‚ Ï€ÎµÏÎ¹Î»Î®ÏˆÎµÎ¹Ï‚. Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±.

--- Î Î¥Î›Î©ÎÎ‘Î£ Î‘: ÎŸ Î”Î•ÎšÎ‘Î›ÎŸÎ“ÎŸÎ£ Î¤Î—Î£ ÎšÎ‘Î›Î—Î£ ÎÎŸÎœÎŸÎ˜Î•Î¤Î—Î£Î—Î£ ---
Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ Î‘Î¥Î£Î¤Î—Î¡Î‘ Î¼Îµ [ÎÎ‘Î™/ÎŸÎ§Î™/ÎœÎ•Î¡Î™ÎšÎ©Î£] ÎºÎ±Î¹ Î¤Î•ÎšÎœÎ—Î¡Î™Î©Î£Î— Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÎ·Î¼ÎµÎ¯Î¿:

1. ÎˆÎ³Î¹Î½Îµ Ï€ÏÎ¿-ÎºÎ¿Î¹Î½Î¿Î²Î¿Ï…Î»ÎµÏ…Ï„Î¹ÎºÎ® Î´Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·; 
   - 1.1. Î‘Î½ Î½Î±Î¹, Î´Î¹Î®ÏÎºÎµÏƒÎµ Î Î•Î¡Î™Î£Î£ÎŸÎ¤Î•Î¡ÎŸ Î® Î›Î™Î“ÎŸÎ¤Î•Î¡ÎŸ Î±Ï€ÏŒ 14 Î·Î¼Î­ÏÎµÏ‚; (Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Ï„Î¹Ï‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚ Ï€Î¿Ï… ÏƒÎ¿Ï… Î´Î¯Î½Î¿Î½Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ Opengov).
   - 1.2. Î Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÏ„Î·ÎºÎ±Î½ Ï„Î± ÎµÏ…ÏÎ®Î¼Î±Ï„Î± ÏƒÎµ Î¾ÎµÏ‡Ï‰ÏÎ¹ÏƒÏ„Î® Î­ÎºÎ¸ÎµÏƒÎ· Ï€Î¿Ï… ÏƒÏ…Î½ÏŒÎ´ÎµÏ…Îµ Ï„Î¿ Î½Î¿Î¼Î¿ÏƒÏ‡Î­Î´Î¹Î¿;

2. ÎŸ Î¼Î­ÏƒÎ¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Ï€Î¿Ï… Î´ÏŒÎ¸Î·ÎºÎµ ÏƒÏ„Î·Î½ Î±ÎºÏÏŒÎ±ÏƒÎ· Ï†Î¿ÏÎ­Ï‰Î½ Ï…Ï€ÎµÏÎ²Î±Î¯Î½ÎµÎ¹ Ï„Î± 5 Î»ÎµÏ€Ï„Î¬; (Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎµ ÎµÎ½Î´ÎµÎ¯Î¾ÎµÎ¹Ï‚ ÏƒÏ„Î± ÎºÎµÎ¯Î¼ÎµÎ½Î±).

3. Î£Ï…Î³ÎºÏÎ¯Î½Î¿Î½Ï„Î±Ï‚ Ï„Î¿ Î±ÏÏ‡Î¹ÎºÏŒ ÏƒÏ‡Î­Î´Î¹Î¿ Î¼Îµ Ï„Î¿ Ï„ÎµÎ»Î¹ÎºÏŒ, Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Ï„Î¬Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… ÎµÎ¼Ï†Î±Î½Î¯ÏƒÏ„Î·ÎºÎ±Î½ Ï‰Ï‚ (Ï€Î¿Î»Ï…-)Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¯ÎµÏ‚; (Î¨Î¬Î¾Îµ Î³Î¹Î± "Î›Î¿Î¹Ï€Î­Ï‚/Î•Ï€ÎµÎ¯Î³Î¿Ï…ÏƒÎµÏ‚ Î´Î¹Î±Ï„Î¬Î¾ÎµÎ¹Ï‚" ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚ Ï„Î¿Ï… Î½ÏŒÎ¼Î¿Ï… Ï€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î¬ÏƒÏ‡ÎµÏ„ÎµÏ‚ Î¼Îµ Ï„Î¿Î½ Ï„Î¯Ï„Î»Î¿).

4. Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Â«ÎµÏ€Î¹Ï‡ÏÏÏƒÏ‰ÏƒÎ·Â» (gold-plating); (Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÎµÎ¸Î½Î¹ÎºÏÎ½ Î²Î±ÏÏÎ½ ÏƒÎµ Î´Î¹ÎµÎ¸Î½ÎµÎ¯Ï‚ ÎºÎ±Î½ÏŒÎ½ÎµÏ‚).

5. Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÎ¹Î´Î¹ÎºÎ­Ï‚ Î´Î¹Î±Ï„Î¬Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Î±Ï†Î¿ÏÎ¿ÏÎ½ Ï„Î¿Ï…Ï‚ Î¿ÏÎµÎ¹Î½Î¿ÏÏ‚ ÏŒÎ³ÎºÎ¿Ï…Ï‚ ÎºÎ±Î¹ Ï„Î± Î½Î·ÏƒÎ¹Î¬; (Î¡Î®Ï„ÏÎ± ÎÎ·ÏƒÎ¹Ï‰Ï„Î¹ÎºÏŒÏ„Î·Ï„Î±Ï‚ - ÎˆÎ»ÎµÎ³Î¾Îµ Ï„Î·Î½ ÎˆÎºÎ¸ÎµÏƒÎ· Î£Ï…Î½ÎµÏ€ÎµÎ¹ÏÎ½).

6. Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Ï„ÎµÎºÎ¼Î·ÏÎ¹Ï‰Î¼Î­Î½Î· Î±Î½Î¬Î»Ï…ÏƒÎ· ÎºÏŒÏƒÏ„Î¿Ï…Ï‚-Ï‰Ï†Î­Î»ÎµÎ¹Î±Ï‚; (Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î ÎŸÎ£ÎŸÎ¤Î™ÎšÎ‘ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î³Î¹Î± Ï„Î¿ ÎŸÎ¦Î•Î›ÎŸÎ£ Î® Î¼ÏŒÎ½Î¿ Î±ÏŒÏÎ¹ÏƒÏ„ÎµÏ‚ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î­Ï‚; Î¤Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î·Î½ Î­ÎºÎ¸ÎµÏƒÎ· Î“Î›Îš).

7. Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Î¹Î±Ï„Î¬Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Î±Ï€Î»Î¿Ï…ÏƒÏ„ÎµÏÎ¿Ï…Î½/ÎºÎ±Ï„Î±ÏÎ³Î¿ÏÎ½ Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ­Ï‚ ÎµÏ€Î¹Î²Î±ÏÏÎ½ÏƒÎµÎ¹Ï‚; (Î‰ Î¼Î®Ï€Ï‰Ï‚ Ï€ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î½ Î³ÏÎ±Ï†ÎµÎ¹Î¿ÎºÏÎ±Ï„Î¯Î±;).

8. Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÎ¾Î¿Ï…ÏƒÎ¹Î¿Î´Î¿Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î·Î½ Î­ÎºÎ´Î¿ÏƒÎ· Î¥Ï€Î¿Ï…ÏÎ³Î¹ÎºÏÎ½ Î‘Ï€Î¿Ï†Î¬ÏƒÎµÏ‰Î½ Î³Î¹Î± Î¸Î­Î¼Î±Ï„Î± Ï„Î¿Ï… ÎºÏ…ÏÎ¯Ï‰Ï‚ Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…; (Î¤Î¿ Ï†Î±Î¹Î½ÏŒÎ¼ÎµÎ½Î¿ Ï„Î·Ï‚ "Î›ÎµÏ…ÎºÎ®Ï‚ Î•Ï€Î¹Ï„Î±Î³Î®Ï‚" - ÎœÎ­Ï„ÏÎ± Ï„ÎµÏ‚).

9. Î‘Î½Î±Ï†Î­ÏÎ¿Î½Ï„Î±Î¹ ÎµÎ¹Î´Î¹ÎºÏŒÏ„ÎµÏÎ¿Î¹ Î¼Î·Ï‡Î±Î½Î¹ÏƒÎ¼Î¿Î¯ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚; (Î§ÏÎ¿Î½Î¿Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î±, Ï€Î»Î±Ï„Ï†ÏŒÏÎ¼ÎµÏ‚).

10. Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´Ï…ÏƒÎºÎ¿Î»Î¯ÎµÏ‚ ÏƒÏ„Î·Î½ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Î¿Ï… Î½ÏŒÎ¼Î¿Ï…; (Î£Ï…Î½Ï„Î±ÎºÏ„Î¹ÎºÎ¬ Î»Î¬Î¸Î·, Î±Î¿ÏÎ¹ÏƒÏ„Î¯ÎµÏ‚).

--- Î Î¥Î›Î©ÎÎ‘Î£ Î’: Î•Î›Î•Î“Î§ÎŸÎ£ Î£Î¥ÎœÎ’Î‘Î¤ÎŸÎ¤Î—Î¤Î‘Î£ ÎœÎ• Î¤ÎŸ "Î•Î“Î§Î•Î™Î¡Î™Î”Î™ÎŸ 2020" ---
ÎˆÎ»ÎµÎ³Î¾Îµ Ï„Î·Î½ "Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½ÎµÏ€ÎµÎ¹ÏÎ½ Î¡ÏÎ¸Î¼Î¹ÏƒÎ·Ï‚" (Î‘Î£Î¡) ÎºÎ±Î¹ Ï„Î·Î½ Î‘Î¹Ï„Î¹Î¿Î»Î¿Î³Î¹ÎºÎ® ÎˆÎºÎ¸ÎµÏƒÎ·:
* **Î‘ÏÏ‡Î® Ï„Î·Ï‚ Î‘Î½Î±Î³ÎºÎ±Î¹ÏŒÏ„Î·Ï„Î±Ï‚:** Î¤ÎµÎºÎ¼Î·ÏÎ¹ÏÎ½ÎµÏ„Î±Î¹ Ï€ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î³Î¹Î±Ï„Î¯ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ Î½Î­Î¿Ï‚ Î½ÏŒÎ¼Î¿Ï‚;
* **Î Î¯Î½Î±ÎºÎ±Ï‚ Î¤ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î¿ÏÎ¼ÎµÎ½Ï‰Î½ Î”Î¹Î±Ï„Î¬Î¾ÎµÏ‰Î½:** Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÎ±Ï†Î®Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Ï€Î±Î»Î±Î¹Î¿Ï vs Î½Î­Î¿Ï… Î´Î¹ÎºÎ±Î¯Î¿Ï…;
* **Î”Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÏŒ Î’Î¬ÏÎ¿Ï‚:** Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÏ„Î±Î¹ Ï„Î¿ ÎºÏŒÏƒÏ„Î¿Ï‚ ÏƒÎµ Î±Î½Î¸ÏÏ‰Ï€Î¿ÏÏÎµÏ‚ Î³Î¹Î± Ï„Î¿Ï…Ï‚ Ï€Î¿Î»Î¯Ï„ÎµÏ‚/Ï…Ï€Î±Î»Î»Î®Î»Î¿Ï…Ï‚;

--- Î Î¥Î›Î©ÎÎ‘Î£ Î“: Î“Î›Î©Î£Î£Î™ÎšÎŸÎ£ Î•Î›Î•Î“Î§ÎŸÎ£ & ÎšÎ¡Î™Î¤Î™ÎšÎ— (LINGUISTIC AUDIT) ---
* **ÎÏÎ»Î¹Î½Î· Î“Î»ÏÏƒÏƒÎ±:** Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ ÏŒÏÎ¿Ï…Ï‚ ÏŒÏ€Ï‰Ï‚ "ÎµÎ¾Î¿ÏÎ¸Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚", "Î²Î­Î»Ï„Î¹ÏƒÏ„Î· Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®", "ÎºÎ±Î¹Î½Î¿Ï„Î¿Î¼Î¯Î±" Î±Î½ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½Ï„Î±Î¹ Ï‡Ï‰ÏÎ¯Ï‚ ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ Î½Î¿Î¼Î¹ÎºÏŒ Î¿ÏÎ¹ÏƒÎ¼ÏŒ.
* **Î‘Î¿ÏÎ¹ÏƒÏ„Î¯Î±:** Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ Ï†ÏÎ¬ÏƒÎµÎ¹Ï‚ ÏŒÏ€Ï‰Ï‚ "ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎºÏÎ¯ÏƒÎ· Ï„Î¿Ï… Î¿ÏÎ³Î¬Î½Î¿Ï…", "ÎµÎ½Ï„ÏŒÏ‚ ÎµÏ…Î»ÏŒÎ³Î¿Ï… Ï‡ÏÏŒÎ½Î¿Ï…".
* **Î Î¿Î»Ï…Î½Î¿Î¼Î¯Î±:** Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ Î±Î»Ï…ÏƒÎ¯Î´ÎµÏ‚ Ï€Î±ÏÎ±Ï€Î¿Î¼Ï€ÏÎ½ (Ï€.Ï‡. "Î¬ÏÎ¸ÏÎ¿ Î§ Ï„Î¿Ï… Î½.Î‘ ÏŒÏ€Ï‰Ï‚ Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ Î¼Îµ Ï„Î¿ Î½.Î’...").
* **Î£Ï…Î½Ï„Î±ÎºÏ„Î¹ÎºÎ® Î Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î±:** Î•Î½Ï„ÏŒÏ€Î¹ÏƒÎµ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î¬Î½Ï‰ Ï„Ï‰Î½ 50 Î»Î­Î¾ÎµÏ‰Î½.

--- Î¤Î•Î›Î™ÎšÎŸ Î ÎŸÎ¡Î™Î£ÎœÎ‘ (SCORECARD) ---
Î”ÏÏƒÎµ Î²Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î± (0-10) ÎºÎ±Î¹ Ï„Î± 3 ÏƒÎ¿Î²Î±ÏÏŒÏ„ÎµÏÎ± "ÎšÏŒÎºÎºÎ¹Î½Î± Î£Î·Î¼ÎµÎ¯Î±" (Red Flags).
"""

genai.configure(api_key=GOOGLE_API_KEY)

# =============================================================================
# ğŸ› ï¸ Î•Î¡Î“Î‘Î›Î•Î™Î‘ (HEADERS & SEARCH FIX)
# =============================================================================

def get_browser_headers():
    """Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ headers Ï€Î¿Ï… Î¼Î¹Î¼Î¿ÏÎ½Ï„Î±Î¹ Ï„Î¿Î½ Chrome Î³Î¹Î± Î½Î± Î±Ï€Î¿Ï†ÏÎ³Î¿Ï…Î¼Îµ Ï„Î¿ 403."""
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'el-GR,el;q=0.9,en;q=0.8',
        'Referer': 'https://www.google.com/'
    }

def google_search_opengov(law_identifier):
    """Î¨Î¬Ï‡Î½ÎµÎ¹ ÏƒÏ„Î¿ Google Î¼Îµ Î±Î½Ï„Î¹-Î¼Ï€Î»Î¿Îº headers."""
    print(f"ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Opengov Î³Î¹Î±: {law_identifier}...")
    
    query = f"site:opengov.gr {law_identifier} Î´Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·"
    url = f"https://www.google.com/search?q={urllib.parse.quote(query)}"
    
    try:
        # Î§ÏÎ®ÏƒÎ· Ï„Ï‰Î½ headers Î³Î¹Î± Î½Î± Ï†Î±Î¯Î½ÎµÏ„Î±Î¹ ÏƒÎ±Î½ browser
        res = requests.get(url, headers=get_browser_headers(), timeout=10)
        
        if res.status_code == 429:
            print("âš ï¸ Î— Google Î¶Î·Ï„Î¬ÎµÎ¹ CAPTCHA. Î˜Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÏ‰ Ï‡Ï‰ÏÎ¯Ï‚ web data.")
            return None
            
        res.raise_for_status()
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # Î•ÏÏÎµÏƒÎ· link
        for a in soup.find_all('a', href=True):
            href = a['href']
            if 'opengov.gr' in href and 'google' not in href:
                print(f"   âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Link: {href}")
                return href
            # Î‘Î½ ÎµÎ¯Î½Î±Î¹ google redirect url
            if '/url?q=' in href and 'opengov.gr' in href:
                clean_link = href.split('/url?q=')[1].split('&')[0]
                print(f"   âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Link: {clean_link}")
                return clean_link
                
        print("   âš ï¸ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Link.")
        return None

    except Exception as e:
        print(f"   âš ï¸ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚: {e}")
        return None

def fetch_opengov_content(url):
    """ÎšÎ±Ï„ÎµÎ²Î¬Î¶ÎµÎ¹ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î±Ï€ÏŒ Ï„Î¿ Opengov."""
    if not url: return ""
    try:
        res = requests.get(url, headers=get_browser_headers(), timeout=10)
        soup = BeautifulSoup(res.content, 'html.parser')
        for s in soup(["script", "style"]): s.decompose()
        return soup.get_text(separator=' ', strip=True)[:20000]
    except:
        return ""

# =============================================================================
# ğŸ•·ï¸ AUTO DOWNLOADER (PARLIAMENT)
# =============================================================================

def download_parliament_files(url):
    """ÎšÎ±Ï„ÎµÎ²Î¬Î¶ÎµÎ¹ Ï„Î± PDF Î±Ï€ÏŒ Ï„Î· ÏƒÎµÎ»Î¯Î´Î± Ï„Î·Ï‚ Î’Î¿Ï…Î»Î®Ï‚."""
    print(f"ğŸ“¡ Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Î’Î¿Ï…Î»Î®: {url}")
    
    if not os.path.exists(DOWNLOAD_FOLDER):
        os.makedirs(DOWNLOAD_FOLDER)

    try:
        response = requests.get(url, headers=get_browser_headers(), timeout=20)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        doc_types = {
            "Î±Î¹Ï„Î¹Î¿Î»Î¿Î³Î¹ÎºÎ®": "Aitiologiki.pdf",
            "ÏƒÏ‡Î­Î´Î¹Î¿ Î½ÏŒÎ¼Î¿Ï…": "Sxedio_Nomou.pdf",
            "ÏˆÎ·Ï†Î¹ÏƒÎ¸Î­Î½": "Psifisthen.pdf",
            "ÏƒÏ…Î½ÎµÏ€ÎµÎ¹ÏÎ½": "Analysi_Synepeion.pdf",
            "Î³Î»Îº": "Ekthesi_GLK.pdf",
            "ÎµÎ¹Î´Î¹ÎºÎ®": "Eidiki_Ekthesi.pdf",
            "Î´Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·Ï‚": "Ekthesi_Diavouleusis.pdf",
            "Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¯ÎµÏ‚": "Tropologies.pdf"
        }

        downloaded = []
        links = soup.find_all('a', href=True)
        print(f"ğŸ” ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ {len(links)} ÏƒÏ…Î½Î´Î­ÏƒÎ¼Ï‰Î½...")

        for link in links:
            href = link['href']
            text = link.get_text().lower().strip()
            
            if '.pdf' in href or 'UserFiles' in href:
                for keyword, filename in doc_types.items():
                    if keyword in text:
                        full_url = href if href.startswith("http") else "https://www.hellenicparliament.gr" + href
                        
                        if not any(d['name'] == filename for d in downloaded):
                            print(f"   â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î±: {text[:30]}...")
                            try:
                                r = requests.get(full_url, headers=get_browser_headers(), stream=True)
                                path = os.path.join(DOWNLOAD_FOLDER, filename)
                                with open(path, 'wb') as f:
                                    for chunk in r.iter_content(chunk_size=8192):
                                        f.write(chunk)
                                downloaded.append({"path": path, "name": filename})
                            except:
                                pass
                        break
        return downloaded

    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ Î¼Îµ Ï„Î· Î’Î¿Ï…Î»Î®: {e}")
        return []

# =============================================================================
# ğŸ§  AI AUDIT ENGINE
# =============================================================================

def run_full_audit(law_title, parliament_url):
    # 1. Î’ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î± Î”Î¹Î±Î²Î¿ÏÎ»ÎµÏ…ÏƒÎ·Ï‚ (Google Search)
    og_url = google_search_opengov(law_title)
    og_data = fetch_opengov_content(og_url)
    
    # 2. ÎšÎ±Ï„ÎµÎ²Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î± PDF (Parliament Scraper)
    if parliament_url:
        files = download_parliament_files(parliament_url)
    else:
        # Î‘Î½ Î´ÎµÎ½ Î´ÏÏƒÎµÎ¹ URL, ÏˆÎ¬Ï‡Î½Î¿Ï…Î¼Îµ ÏƒÏ„Î¿Î½ Ï†Î¬ÎºÎµÎ»Î¿ Î¼Î®Ï€Ï‰Ï‚ Ï„Î± Î­Ï‡ÎµÎ¹ Î²Î¬Î»ÎµÎ¹ Î¼ÏŒÎ½Î¿Ï‚ Ï„Î¿Ï…
        files = [{"path": os.path.join(DOWNLOAD_FOLDER, f), "name": f} 
                 for f in os.listdir(DOWNLOAD_FOLDER) if f.endswith('.pdf')]

    if not files:
        print("âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÏ‡ÎµÎ¯Î±. ÎŸ Î­Î»ÎµÎ³Ï‡Î¿Ï‚ ÏƒÏ„Î±Î¼Î±Ï„Î¬.")
        return

    # 3. Upload ÏƒÏ„Î¿ Gemini
    print(f"\nğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± {len(files)} Î±ÏÏ‡ÎµÎ¯Ï‰Î½ ÏƒÏ„Î¿ AI...")
    uploaded_files = []
    genai.configure(api_key=GOOGLE_API_KEY)
    
    for f in files:
        try:
            uf = genai.upload_file(f['path'], mime_type="application/pdf")
            print(f"   âœ… Uploaded: {f['name']}")
            uploaded_files.append(uf)
        except Exception as e:
            print(f"   âš ï¸ Error: {e}")

    print("â³ Î‘Î½Î±Î¼Î¿Î½Î® Î³Î¹Î± OCR...", end="")
    while True:
        if all(f.state.name == "ACTIVE" for f in [genai.get_file(uf.name) for uf in uploaded_files]):
            break
        print(".", end="", flush=True)
        time.sleep(2)
    print(" ÎˆÏ„Î¿Î¹Î¼Î¿.")

    # 4. Generate Audit Report
    model = genai.GenerativeModel(model_name="gemini-1.5-pro", system_instruction=SYSTEM_INSTRUCTIONS)
    
    context = f"""
    Î‘ÎÎ¤Î™ÎšÎ•Î™ÎœÎ•ÎÎŸ: {law_title}
    
    Î£Î¤ÎŸÎ™Î§Î•Î™Î‘ Î‘Î ÎŸ Î”Î™Î‘Î”Î™ÎšÎ¤Î¥ÎŸ (Î”Î™Î‘Î’ÎŸÎ¥Î›Î•Î¥Î£Î—):
    {og_data}
    
    Î•ÎÎ¤ÎŸÎ›Î—: Î•ÎºÏ„Î­Î»ÎµÏƒÎµ Ï„Î¿Î½ Î Î»Î®ÏÎ· ÎˆÎ»ÎµÎ³Ï‡Î¿ (Decalogue + Handbook + Linguistics) ÏƒÏ„Î± ÎµÏ€Î¹ÏƒÏ…Î½Î±Ï€Ï„ÏŒÎ¼ÎµÎ½Î± Î±ÏÏ‡ÎµÎ¯Î±.
    """
    
    print("\nğŸ¤– ÎŸ Î•Î»ÎµÎ³ÎºÏ„Î®Ï‚ ÏƒÏ…Î½Ï„Î¬ÏƒÏƒÎµÎ¹ Ï„Î·Î½ Î­ÎºÎ¸ÎµÏƒÎ·... (Î ÎµÏÎ¹Î¼Î­Î½ÎµÏ„Îµ)")
    try:
        response = model.generate_content(uploaded_files + [context])
        print("\n" + "="*60)
        print("ğŸ›ï¸  FULL LEGISLATIVE AUDIT REPORT  ğŸ›ï¸")
        print("="*60)
        print(response.text)
        
        with open("Final_Audit.txt", "w", encoding="utf-8") as f:
            f.write(response.text)
            
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± AI: {e}")

# =============================================================================
# â–¶ï¸ EXECUTION
# =============================================================================
if __name__ == "__main__":
    print("="*60)
    print("ğŸ¤– ULTIMATE AUDITOR (Fixed 403 + Full Checks + Auto Download)")
    print("="*60)
    
    law_in = input("\nğŸ‘‰ Î¤Î¯Ï„Î»Î¿Ï‚ Î® Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ ÎÏŒÎ¼Î¿Ï… (Ï€.Ï‡. 4940/2022): ").strip()
    url_in = input("ğŸ‘‰ Link Î’Î¿Ï…Î»Î®Ï‚ (Paste URL): ").strip()
    
    run_full_audit(law_in, url_in)
